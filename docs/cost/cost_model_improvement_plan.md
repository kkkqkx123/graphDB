# GraphDB 代价模型改进方案

## 概述

本文档提出 GraphDB 查询优化代价模型的分阶段改进方案，参考 PostgreSQL 的设计理念，结合图数据库的特点，逐步建立完善的代价-based 优化体系。

---

## 设计原则

### 渐进式改进

采用分阶段实施策略，每个阶段解决特定问题，逐步提升优化器能力：

- 阶段一：建立基础统计信息收集机制
- 阶段二：实现基础代价计算模型
- 阶段三：引入选择性估计框架
- 阶段四：完善连接和复杂操作代价
- 阶段五：支持自适应和反馈校准

### 单节点适配

针对 GraphDB 作为单节点图数据库的特点：

- 简化分布式相关的网络代价计算
- 重点关注内存和磁盘 I/O 代价
- 优化图遍历和路径查询的代价模型

### 与现有架构兼容

- 复用现有的计划节点结构
- 保持代价接口的一致性
- 逐步替换而非推倒重来

---

## 阶段一：基础统计信息（P0）

### 目标

建立统计信息收集和存储框架，为后续代价计算提供数据基础。

### 统计信息内容

#### 表级统计

针对图数据库的特点，统计信息围绕标签（Tag）和边类型（Edge Type）组织：

- **实体统计**：
  - 标签实例数量（对应关系表的行数）
  - 边类型实例数量
  - 平均实体大小（属性占用的平均空间）
  
- **存储统计**：
  - 数据页数量
  - 索引页数量
  - 数据文件大小

#### 列级统计

针对属性和边的统计：

- **基础统计**：
  - 空值比例
  - 不同值数量
  - 属性平均长度
  
- **分布统计**：
  - 最常见值列表（MCV）及其频率
  - 直方图（用于范围查询）
  - 最小值和最大值

#### 图结构统计

图数据库特有的统计信息：

- **度分布**：
  - 平均入度/出度
  - 度分布直方图
  
- **连通性**：
  - 连通分量数量
  - 图直径估计

### 收集机制

#### 手动收集

提供 ANALYZE 命令支持：

- 全表分析：扫描所有数据收集统计
- 采样分析：基于采样快速估算统计
- 增量分析：仅更新变化较大的表

#### 自动收集

支持统计信息的自动维护：

- 监控数据修改操作（插入、删除、更新）
- 当修改比例超过阈值时触发自动收集
- 可配置自动收集的积极性和时机

### 存储方式

- 统计信息存储在系统表中
- 与数据字典一起持久化
- 支持统计信息的导入导出

---

## 阶段二：基础代价模型（P1）

### 目标

实现基于操作类型的基础代价计算，使不同操作具有可区分的代价值。

### 代价参数体系

参考 PostgreSQL 的设计，建立可配置的代价参数：

#### I/O 代价参数

- **顺序页读取代价**：顺序扫描数据页的代价
- **随机页读取代价**：随机访问数据页的代价（通常高于顺序）
- **索引页读取代价**：访问索引页的代价

#### CPU 代价参数

- **行处理代价**：处理每行数据的 CPU 成本
- **属性访问代价**：访问每个属性的 CPU 成本
- **操作符计算代价**：执行比较、计算等操作的代价
- **图遍历步进代价**：图遍历中每步的额外开销

### 节点代价计算

#### 扫描操作

**全表扫描**：
- 基于表的页数和行数计算
- 公式：页数 × 顺序页代价 + 行数 × 行处理代价

**索引扫描**：
- 基于索引页数和选择性计算
- 包含索引访问和回表两部分代价
- 公式：索引访问代价 + 选择性 × 表访问代价

#### 过滤操作

- 基础代价：输入流的代价
- 条件评估代价：每行条件判断的开销
- 输出调整：根据选择性调整输出行数估计

#### 连接操作

**嵌套循环连接**：
- 外表扫描代价 + 外表行数 × 内表扫描代价
- 适用于小表驱动大表的场景

**哈希连接**：
- 构建哈希表代价 + 探测代价
- 适用于大表连接，无索引支持的场景

**图特定连接**：
- 考虑图遍历的局部性
- 利用度分布信息优化代价估计

#### 图遍历操作

- **基础代价**：起始节点的获取代价
- **扩展代价**：每步遍历的平均代价
- **深度因子**：遍历深度对代价的影响
- **分支因子**：平均邻居数量对代价的影响

### 计划总代价计算

递归累加计划中所有节点的代价：

- 深度优先遍历计划树
- 累加每个节点的执行代价
- 考虑节点间的数据流关系
- 输出总代价和估计行数

---

## 阶段三：选择性估计（P2）

### 目标

实现条件选择性的准确估计，使代价模型能够反映过滤和连接的实际输出行数。

### 等值条件选择性

#### MCV 匹配

如果查询值在统计信息的 MCV 列表中：
- 直接使用 MCV 的频率作为选择性

#### 非 MCV 值

使用均匀分布假设：
- 计算剩余频率（1 - MCV 总频率）
- 除以非 MCV 的不同值数量
- 得到非 MCV 值的平均选择性

### 范围条件选择性

#### 直方图方法

对于范围查询（大于、小于、区间）：

- 确定查询边界落在哪个直方图桶
- 计算该桶内的比例
- 累加前面完整桶的贡献
- 得到总的选择性估计

#### 边界值处理

- 小于条件：累加边界左侧的所有桶
- 大于条件：累加边界右侧的所有桶
- 区间条件：计算两个边界之间的桶

### 复合条件选择性

#### 独立条件

如果多个条件涉及不同属性：
- 分别计算每个条件的选择性
- 将选择性相乘得到总选择性

#### 相关条件

如果条件之间存在相关性：
- 使用多列统计信息
- 或采用保守估计（取最大选择性）

### 连接选择性

#### 等值连接

基于连接属性的不同值数量：
- 选择性 = 1 / max(左表不同值数, 右表不同值数)
- 考虑空值的影响

#### 图连接

考虑图结构的特性：
- 利用度分布信息
- 考虑边的方向性
- 估计路径存在的可能性

---

## 阶段四：高级特性（P3）

### 复杂操作代价

#### 聚合操作

- 分组代价：基于分组键的不同值数量
- 聚合函数代价：不同聚合函数的 CPU 开销
- 内存使用：哈希聚合 vs 排序聚合的选择

#### 排序操作

- 数据量较小时：内存排序代价
- 数据量较大时：外部排序代价（考虑磁盘 I/O）
- 利用索引避免排序的代价比较

#### 路径查询

- 最短路径：基于图的 BFS/DFS 代价模型
- 全路径查询：考虑路径数量和长度
- 可变长度路径：基于平均路径长度的估计

### 缓存感知优化

#### 计划缓存代价

改进查询计划缓存的代价计算：

- 使用实际估算的计划总代价
- 考虑计划的复杂度和执行时间
- 支持基于代价的缓存淘汰策略

#### 执行统计反馈

收集实际执行统计：

- 实际执行时间
- 实际输出行数
- 内存使用峰值
- 磁盘 I/O 次数

---

## 阶段五：自适应优化（P4）

### 统计信息校准

基于实际执行结果校准统计信息：

- 比较估计行数与实际行数
- 计算统计信息的误差率
- 自动调整统计信息的可信度

### 代价参数自适应

根据实际执行性能调整代价参数：

- 监测不同操作的实际耗时
- 拟合最优的代价参数值
- 支持工作负载特定的参数调优

### 计划演进

基于历史执行数据改进计划选择：

- 记录计划的实际性能
- 识别估计偏差大的场景
- 优化后续查询的计划选择

---

## 实施建议

### 优先级排序

| 阶段 | 功能 | 优先级 | 工作量 | 收益 |
|-----|------|-------|-------|------|
| 一 | 基础统计信息 | P0 | 小 | 高 |
| 二 | 基础代价模型 | P1 | 小 | 高 |
| 三 | 选择性估计 | P2 | 中 | 中 |
| 四 | 高级操作代价 | P3 | 中 | 中 |
| 五 | 自适应优化 | P4 | 大 | 低 |

### 与现有代码集成

#### 最小改动方案

1. 复用现有的 `CostEstimate` 简化结构
2. 在 `PlanNode` trait 中增加带上下文的代价估算方法
3. 统计信息存储复用现有的统计管理器
4. 逐步替换硬编码的代价值为动态计算

#### 向后兼容

- 保持现有的 `cost()` 方法作为后备
- 新增 `estimate_cost()` 方法提供增强功能
- 统计信息缺失时回退到默认值

### 测试策略

#### 单元测试

- 测试各节点类型的代价计算
- 验证选择性估计的准确性
- 测试统计信息的收集和更新

#### 集成测试

- 端到端查询计划验证
- 代价模型对计划选择的影响
- 缓存代价计算的准确性

#### 性能测试

- 对比改进前后的计划质量
- 测试统计信息收集的开销
- 验证自适应优化的效果

---

## 总结

本改进方案通过五个阶段逐步建立完善的代价模型：

1. **阶段一** 建立数据基础，收集必要的统计信息
2. **阶段二** 实现基础代价计算，使不同操作可区分
3. **阶段三** 引入选择性估计，准确预测输出行数
4. **阶段四** 完善复杂操作，支持图数据库特有场景
5. **阶段五** 实现自适应优化，持续改进模型准确性

通过渐进式实施，可以在保证系统稳定的前提下，逐步提升查询优化器的能力，最终实现对复杂图查询的高效优化。
